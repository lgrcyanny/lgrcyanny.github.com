<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>How to Use Scala UDF and UDAF in PySpark | CyannyLive</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Spark DataFrame API provides efficient and easy-to-use operations to do analysis on distributed collection of data. Many users love the Pyspark API, which is more usable than scala API. Sometimes when">
<meta property="og:type" content="article">
<meta property="og:title" content="How to Use Scala UDF and UDAF in PySpark">
<meta property="og:url" content="http://www.cyanny.com/2017/09/15/spark-use-scala-udf-udaf-in-pyspark/index.html">
<meta property="og:site_name" content="CyannyLive">
<meta property="og:description" content="Spark DataFrame API provides efficient and easy-to-use operations to do analysis on distributed collection of data. Many users love the Pyspark API, which is more usable than scala API. Sometimes when">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/761b7938ly1fjmeol1jg8j20s405odim.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/761b7938ly1fjmeofgzbmj210k06igot.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/761b7938ly1fjmer43xfnj20kw0ckt8z.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/761b7938ly1fjmeopknh4j20a0061748.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/761b7938ly1fjmeo7vk38j210c0fy48j.jpg">
<meta property="article:published_time" content="2017-09-15T03:16:33.000Z">
<meta property="article:modified_time" content="2017-09-17T05:23:32.000Z">
<meta property="article:author" content="Cyanny Liang">
<meta property="article:tag" content="spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://wx1.sinaimg.cn/mw690/761b7938ly1fjmeol1jg8j20s405odim.jpg">
<meta name="twitter:creator" content="@lgrcyanny">
<link rel="publisher" href="lgrcyanny">
<meta property="fb:admins" content="lgrcyanny">
<meta property="fb:app_id" content="lgrcyanny">
  
  
    <link rel="icon" href="favicon.ico">
  
  <link href='//fonts.useso.com/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-40624708-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
<meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="CyannyLive" type="application/atom+xml">
</head>
<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/." id="logo"><i class="logo"></i><span class="site-title">CyannyLive</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/jianyinjietu">剪影截图</a>
        
      </nav>
      
      <nav id="sub-nav">
        <div class="profile" id="profile-nav">
          <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/avatar.png"><i class="fa fa-caret-down"></i></a>
        </div>
      </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.cyanny.com"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
      
        <td><a class="main-nav-link" href="/.">Home</a></td>
      
        <td><a class="main-nav-link" href="/archives">Archives</a></td>
      
        <td><a class="main-nav-link" href="/categories">Categories</a></td>
      
        <td><a class="main-nav-link" href="/tags">Tags</a></td>
      
        <td><a class="main-nav-link" href="/jianyinjietu">剪影截图</a></td>
      
      <td>
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.cyanny.com"></form>
      </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
  	<div class="base-info profile-block">
		  <img id="avatar" src="/css/images/avatar.png">
      <h2 id="name">Cyanny Liang</h2>
      <h3 id="title">AI System Architecture</h3>
      <span id="location"><i class="fa fa-map-marker"></i>Beijing, China</span>
      <a id="follow" target="_blank" rel="noopener" href="https://github.com/lgrcyanny/">FOLLOW</a>
  	</div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        64
        <span>posts</span>
      </div>
      <div class="article-info-block">
        38
        <span>tags</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
        
          <td><a href="http://github.com/lgrcyanny" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
        
          <td><a href="https://twitter.com/lgrcyanny" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
        
          <td><a href="https://www.facebook.com/CyannyLIANG" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
        
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
        
        </tr>
      </table>
    </div>
    
  </div>
</aside>
      
      <section id="main"><article id="post-spark-use-scala-udf-udaf-in-pyspark" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      How to Use Scala UDF and UDAF in PySpark
    </h1>
  

        <div class="article-meta">
          <div class="article-date">
  <i class="fa fa-calendar"></i>
  <a href="/2017/09/15/spark-use-scala-udf-udaf-in-pyspark/">
    <time datetime="2017-09-15T03:16:33.000Z" itemprop="datePublished">2017-09-15</time>
  </a>
</div>
          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Spark DataFrame API provides efficient and easy-to-use operations to do analysis on distributed collection of data. Many users love the Pyspark API, which is more usable than scala API. Sometimes when we use UDF in pyspark, the performance will be a problem. How about implementing these UDF in scala, and call them in pyspark? BTW, in spark 2.0, UDAF can only be defined in scala, and how to use it in pyspark? Let’s have a try~</p>
<a id="more"></a>

<h2 id="Use-Scala-UDF-in-PySpark"><a href="#Use-Scala-UDF-in-PySpark" class="headerlink" title="Use Scala UDF in PySpark"></a>Use Scala UDF in PySpark</h2><p><strong>1. define scala udf</strong></p>
<p>Suppose we want to calculate string length, lets define it in scala UDF.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StringLength</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getStringLength</span></span>(s: <span class="type">String</span>) = s.length</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getFun</span></span>(): <span class="type">UserDefinedFunction</span> = udf(getStringLength _)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>2. use udf in python</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> Column</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> _to_java_column</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> _to_seq</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col</span><br><span class="line"> </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;scala_udf_test&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">string_length</span>(<span class="params">col</span>):</span></span><br><span class="line">    _string_length = sc._jvm.com.learning.StringLength.getFun()</span><br><span class="line">    <span class="keyword">return</span> Column(_string_length.apply(_to_seq(sc, [col], _to_java_column)))</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span>():</span></span><br><span class="line">    rows = [</span><br><span class="line">        (<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;aaa&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k2&quot;</span>, <span class="string">&quot;dd&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k3&quot;</span>, <span class="string">&quot;cc&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k4&quot;</span>, <span class="string">&quot;eee&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">    df = spark.createDataFrame(rows, [<span class="string">&#x27;key&#x27;</span>, <span class="string">&#x27;value&#x27;</span>])</span><br><span class="line">    df.show(<span class="number">50</span>)</span><br><span class="line">    df.select(col(<span class="string">&quot;key&quot;</span>), string_length(col(<span class="string">&quot;value&quot;</span>))).show()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    process()</span><br></pre></td></tr></table></figure>
<p><strong>3. submit the app</strong></p>
<p>compile the scala code and submit python files with –jars</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --jars testing/learning<span class="number">-1.0</span><span class="number">.0</span>-<span class="type">SNAPSHOT</span>.jar udf_test.py</span><br></pre></td></tr></table></figure>
<p>the output would be:</p>
<table>
<thead>
<tr>
<th>key</th>
<th>value</th>
</tr>
</thead>
<tbody><tr>
<td>k1</td>
<td>3</td>
</tr>
<tr>
<td>k2</td>
<td>2</td>
</tr>
<tr>
<td>k3</td>
<td>2</td>
</tr>
<tr>
<td>k4</td>
<td>3</td>
</tr>
</tbody></table>
<p><strong>4. performance analysis</strong></p>
<p>let’s explain the scala UDF in Python<br><img src="http://wx1.sinaimg.cn/mw690/761b7938ly1fjmeol1jg8j20s405odim.jpg" alt="scala udf physical plan"><br>the Project Plan is Scala UDF</p>
<p>and if we implement Python UDF as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">py_slen = udf(<span class="keyword">lambda</span> s: <span class="built_in">len</span>(s), IntegerType())</span><br><span class="line">df_with_python_udf = (df.select(col(<span class="string">&quot;key&quot;</span>), py_slen(<span class="string">&quot;value&quot;</span>).alias(<span class="string">&quot;slen&quot;</span>)).orderBy(col(<span class="string">&quot;slen&quot;</span>).desc()))</span><br></pre></td></tr></table></figure>
<p>the Python plan is:<br><img src="http://wx4.sinaimg.cn/mw690/761b7938ly1fjmeofgzbmj210k06igot.jpg" alt="python udf physical plan"><br>the UDF plan is different, which is BatchEvalPython.<br>It can prove that when use scala UDF in python, the evaluation is in JVM and data will not exchange with Python worker. And the performance should be improved.</p>
<p>I evaluated the performance in local environment with 4cores and 2GB memory, and generated 10million rows for each test, the result is as follows:<br><img src="http://wx2.sinaimg.cn/mw690/761b7938ly1fjmer43xfnj20kw0ckt8z.jpg" alt="scala vs python string len udf"><br><strong>Scala UDF is 1.89 times Python UDF</strong></p>
<p><strong>And then I implemented another UDF in Scala and Python with regex string parsing</strong>, the performance is<br><img src="http://wx3.sinaimg.cn/mw690/761b7938ly1fjmeopknh4j20a0061748.jpg" alt="scala vs python string regex parsing"></p>
<p><strong>Scala udf is 2.23 times Python REGEX String Parsing UDF</strong></p>
<p>the Scala UDF is defined as follows:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Created by lgrcyanny on 17/9/13.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StringParse</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">STRING_PATTERN</span> = <span class="string">&quot;&quot;</span><span class="string">&quot;(a.*b)&quot;</span><span class="string">&quot;&quot;</span>.r</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parseString</span></span>(str: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> matched = <span class="type">STRING_PATTERN</span>.findFirstMatchIn(str)</span><br><span class="line">    <span class="keyword">if</span> (matched.isEmpty) &#123;</span><br><span class="line">      <span class="string">&quot;&quot;</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      matched.get.group(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getFun</span></span>() = udf(parseString _ )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Python string parse UDF  vs Scala UDF:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> Column</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> _to_java_column</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> _to_seq</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> length</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> IntegerType</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_word</span>(<span class="params">length</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;get random word for generate rows&quot;&quot;&quot;</span></span><br><span class="line">    letters = string.ascii_lowercase</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join([random.choice(letters) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length)])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_rows</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;generate rows in key value pair&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># generate rows</span></span><br><span class="line">    letters = <span class="string">&quot;abcdefghijklmnopqrstuvwxyz&quot;</span></span><br><span class="line">    rows = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="built_in">id</span> = random.randint(<span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line">        slen = random.randint(<span class="number">0</span>, <span class="number">20</span>)</span><br><span class="line">        word = random_word(slen)</span><br><span class="line">        rows.append((<span class="built_in">id</span>, letters))</span><br><span class="line">    <span class="keyword">return</span> rows</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">string_parse</span>(<span class="params">col</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;scala udf parse string&quot;&quot;&quot;</span></span><br><span class="line">    _string_parse = sc._jvm.com.learning.StringParse.getFun()</span><br><span class="line">    <span class="keyword">return</span> Column(_string_parse.apply(_to_seq(sc, [col], _to_java_column)))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_regex_udf</span>(<span class="params">n=<span class="number">1000</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;test udf with regex parse&quot;&quot;&quot;</span></span><br><span class="line">    rows = generate_rows(n)</span><br><span class="line">    df = spark.createDataFrame(rows, [<span class="string">&#x27;key&#x27;</span>, <span class="string">&#x27;value&#x27;</span>])</span><br><span class="line">    df.show(<span class="number">20</span>)</span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(a.*b)&quot;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_string</span>(<span class="params"><span class="built_in">str</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;parse string with python regex&quot;&quot;&quot;</span></span><br><span class="line">        matched = re.search(pattern, <span class="built_in">str</span>)</span><br><span class="line">        <span class="keyword">if</span> matched:</span><br><span class="line">            <span class="keyword">return</span> matched.group(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    py_parse_str = udf(parse_string, StringType())</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    df_with_python_udf = (df.select(col(<span class="string">&quot;key&quot;</span>), py_parse_str(col(<span class="string">&quot;value&quot;</span>)).alias(<span class="string">&quot;parsed_value&quot;</span>))</span><br><span class="line">                          .<span class="built_in">filter</span>(length(col(<span class="string">&quot;parsed_value&quot;</span>)) &gt; <span class="number">0</span>))</span><br><span class="line">    df_with_python_udf.explain(<span class="literal">True</span>)</span><br><span class="line">    df_with_python_udf.show()</span><br><span class="line">    print(<span class="string">&quot;matched rows: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(df_with_python_udf.count()))</span><br><span class="line">    print(<span class="string">&quot;duration for python regex parse: &#123;&#125;s&quot;</span>.<span class="built_in">format</span>(time.time() - start_time))</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    df_with_scala_udf = (df.select(col(<span class="string">&quot;key&quot;</span>), string_parse(col(<span class="string">&quot;value&quot;</span>)).alias(<span class="string">&quot;parsed_value&quot;</span>))</span><br><span class="line">                          .<span class="built_in">filter</span>(length(col(<span class="string">&quot;parsed_value&quot;</span>)) &gt; <span class="number">0</span>))</span><br><span class="line">    df_with_python_udf.explain(<span class="literal">True</span>)</span><br><span class="line">    df_with_scala_udf.show()</span><br><span class="line">    print(<span class="string">&quot;matched rows: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(df_with_scala_udf.count()))</span><br><span class="line">    print(<span class="string">&quot;duration for scala regex parse: &#123;&#125;s&quot;</span>.<span class="built_in">format</span>(time.time() - start_time))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>5. Conclusion</strong></p>
<p>Databricks used to give a performance for Python vs Scala DataFrame and RDD API:<br><img src="http://wx2.sinaimg.cn/mw690/761b7938ly1fjmeo7vk38j210c0fy48j.jpg" alt="databricks performance"></p>
<p>the blog is <a target="_blank" rel="noopener" href="https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html">here</a>.<br>The performance is a running group-aggregation on 10 million integer pairs on a single machince. The Scala DF is almost 5 times Python lambda function in RDD Python.</p>
<p>Even though, the Scala UDF is not 5 times Python UDF, about 2 times in my test, using scala UDF can improve performance indeed.</p>
<h2 id="Use-Scala-UDAF-in-PySpark"><a href="#Use-Scala-UDAF-in-PySpark" class="headerlink" title="Use Scala UDAF in PySpark"></a>Use Scala UDAF in PySpark</h2><p>UDAF now only supports defined in Scala and Java(spark 2.0)</p>
<p><strong>1. define scala UDAF</strong></p>
<p>when define UDAF, it must extend class <code>UserDefinedAggregateFunction</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.&#123;<span class="type">MutableAggregationBuffer</span>, <span class="type">UserDefinedAggregateFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">ArrayType</span>, <span class="type">DataType</span>, <span class="type">StringType</span>, <span class="type">StructType</span>&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">GroupConcat</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span> = <span class="keyword">new</span> <span class="type">StructType</span>().add(<span class="string">&quot;s&quot;</span>, <span class="type">StringType</span>)</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = <span class="keyword">new</span> <span class="type">StructType</span>().add(<span class="string">&quot;buff&quot;</span>, <span class="type">ArrayType</span>(<span class="type">StringType</span>))</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span> = <span class="type">StringType</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer.update(<span class="number">0</span>, <span class="type">ArrayBuffer</span>.empty[<span class="type">String</span>])</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>, input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (!input.isNullAt(<span class="number">0</span>)) &#123;</span><br><span class="line">      buffer.update(<span class="number">0</span>, buffer.getSeq[<span class="type">String</span>](<span class="number">0</span>) :+ input.getString(<span class="number">0</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>, buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer1.update(<span class="number">0</span>, buffer1.getSeq[<span class="type">String</span>](<span class="number">0</span>) ++ buffer2.getSeq[<span class="type">String</span>](<span class="number">0</span>))</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Any</span> = &#123;</span><br><span class="line">    buffer.getSeq[<span class="type">String</span>](<span class="number">0</span>).mkString(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>2. use UDAF in python</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> Column</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> _to_java_column</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.column <span class="keyword">import</span> _to_seq</span><br><span class="line"> </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;scala_udf_test&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">group_concat</span>(<span class="params">col</span>):</span></span><br><span class="line">    _groupConcat = sc._jvm.com.learning.GroupConcat.apply</span><br><span class="line">    <span class="keyword">return</span> Column(_groupConcat(_to_seq(sc, [col], _to_java_column)))</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span>():</span></span><br><span class="line">    rows = [</span><br><span class="line">        (<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;c&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k2&quot;</span>, <span class="string">&quot;d&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k3&quot;</span>, <span class="string">&quot;e&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;k3&quot;</span>, <span class="string">&quot;f&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">    df = spark.createDataFrame(rows, [<span class="string">&#x27;key&#x27;</span>, <span class="string">&#x27;value&#x27;</span>])</span><br><span class="line">    df.show(<span class="number">50</span>)</span><br><span class="line">    df.groupBy(<span class="string">&quot;key&quot;</span>).agg(group_concat(<span class="string">&quot;value&quot;</span>).alias(<span class="string">&quot;concat&quot;</span>)).show()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    process()</span><br></pre></td></tr></table></figure>
<p><strong>3. submit the app</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-submit --jars testing&#x2F;learning-1.0.0-SNAPSHOT.jar udf_test.py</span><br></pre></td></tr></table></figure>
<p>the output would be:</p>
<table>
<thead>
<tr>
<th>key</th>
<th>cancat</th>
</tr>
</thead>
<tbody><tr>
<td>k1</td>
<td>a,b,c</td>
</tr>
<tr>
<td>k2</td>
<td>d</td>
</tr>
<tr>
<td>k3</td>
<td>e,f</td>
</tr>
</tbody></table>
<p><strong>4. references</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/31640729/spark-sql-replacement-for-mysql-group-concat-aggregate-function">spark-sql-replacement-for-mysql-group-concat-aggregate-function</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/33233737/spark-how-to-map-python-with-scala-or-java-user-defined-functions">spark-how-to-map-python-with-scala-or-java-user-defined-functions</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.cyanny.com/2017/09/15/spark-use-scala-udf-udaf-in-pyspark/" data-id="ckjk20xmf000l9bwrb01h69xg" class="article-share-link">Share</a>
      
        <a href="http://www.cyanny.com/2017/09/15/spark-use-scala-udf-udaf-in-pyspark/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/12/29/ppmml-publish/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ppmml publish today
        
      </div>
    </a>
  
  
    <a href="/2017/08/30/my-first-commit-to-spark-community/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">My First Commit to Spark Community</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">recents</h3>
    <div class="widget">
      <ul id="recent-post" class="no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category"></p>
              <p class="item-title"><a href="/2020/12/27/an-introduction-to-bayesian-networks/" class="title">An Introduction to Bayesian Networks</a></p>
              <p class="item-date"><time datetime="2020-12-27T10:54:04.000Z" itemprop="datePublished">2020-12-27</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-inner">
              <p class="item-category"></p>
              <p class="item-title"><a href="/2020/12/25/strucutre-learning-algorithm-notears/" class="title">Strucutre Learning Algorithm NOTEARS</a></p>
              <p class="item-date"><time datetime="2020-12-25T14:01:59.000Z" itemprop="datePublished">2020-12-25</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-inner">
              <p class="item-category"></p>
              <p class="item-title"><a href="/2020/09/13/akka-http-notes/" class="title">Akka http notes</a></p>
              <p class="item-date"><time datetime="2020-09-13T13:47:31.000Z" itemprop="datePublished">2020-09-13</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-inner">
              <p class="item-category"></p>
              <p class="item-title"><a href="/2018/08/04/java-performance-notes-monitoring-tools/" class="title">Java Performance Toolbox</a></p>
              <p class="item-date"><time datetime="2018-08-04T10:24:34.000Z" itemprop="datePublished">2018-08-04</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-inner">
              <p class="item-category"></p>
              <p class="item-title"><a href="/2018/07/16/big-data-expert/" class="title">Big Data And ML Learning</a></p>
              <p class="item-date"><time datetime="2018-07-16T00:33:12.000Z" itemprop="datePublished">2018-07-16</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/distributed-system/">Distributed System</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/distributed-system/life/">Life</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">Hadoop</a><span class="category-list-count">16</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/hbase/">HBase</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/hive/">Hive</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/javascript/">JavaScript</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">Life</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">Linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/network/">Network</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/nodejs/">Nodejs</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system-analysis-and-design/">System Analysis and Design</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">tag cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/agile/" style="font-size: 10px;">Agile</a> <a href="/tags/akka/" style="font-size: 10px;">Akka</a> <a href="/tags/akka-scala/" style="font-size: 10px;">Akka, Scala</a> <a href="/tags/algorithm/" style="font-size: 13.33px;">Algorithm</a> <a href="/tags/big-data/" style="font-size: 13.33px;">Big Data</a> <a href="/tags/causal-inference-ai/" style="font-size: 11.67px;">Causal Inference, AI</a> <a href="/tags/design/" style="font-size: 15px;">Design</a> <a href="/tags/hbase/" style="font-size: 16.67px;">HBase</a> <a href="/tags/hadoop/" style="font-size: 18.33px;">Hadoop</a> <a href="/tags/hive/" style="font-size: 10px;">Hive</a> <a href="/tags/javascript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/language/" style="font-size: 10px;">Language</a> <a href="/tags/learn/" style="font-size: 10px;">Learn</a> <a href="/tags/learning/" style="font-size: 20px;">Learning</a> <a href="/tags/linux/" style="font-size: 11.67px;">Linux</a> <a href="/tags/machine-learning/" style="font-size: 13.33px;">Machine Learning</a> <a href="/tags/mapreduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/methodology/" style="font-size: 10px;">Methodology</a> <a href="/tags/network/" style="font-size: 10px;">Network</a> <a href="/tags/node-js/" style="font-size: 10px;">Node.js</a> <a href="/tags/research/" style="font-size: 16.67px;">Research</a> <a href="/tags/resource/" style="font-size: 10px;">Resource</a> <a href="/tags/scala/" style="font-size: 15px;">Scala</a> <a href="/tags/spark/" style="font-size: 10px;">Spark</a> <a href="/tags/systemanalysis/" style="font-size: 15px;">SystemAnalysis</a> <a href="/tags/vps/" style="font-size: 11.67px;">VPS</a> <a href="/tags/algorithm/" style="font-size: 16.67px;">algorithm</a> <a href="/tags/apache-storm/" style="font-size: 10px;">apache storm</a> <a href="/tags/java-performance/" style="font-size: 10px;">java performance</a> <a href="/tags/learning/" style="font-size: 11.67px;">learning</a> <a href="/tags/life/" style="font-size: 10px;">life</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine learning</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/nodejs/" style="font-size: 10px;">nodejs</a> <a href="/tags/sort/" style="font-size: 11.67px;">sort</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/spark-streaming/" style="font-size: 10px;">spark streaming</a> <a href="/tags/%E8%AF%97%E8%AF%9D/" style="font-size: 10px;">诗话</a>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Cyanny Liang
    </div>
  </div>
</footer>
    

<script>
  var disqus_shortname = 'lgrcyanny';
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


  </div>
</body>
</html>