<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>spark streaming exactly-once analysis | CyannyLive</title>

  
  <meta name="author" content="Cyanny Liang">
  

  
  <meta name="description" content="Do not go gentle into that good night">
  

  
  
  <meta name="keywords" content="spark streaming">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="spark streaming exactly-once analysis"/>

  <meta property="og:site_name" content="CyannyLive"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="CyannyLive" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">CyannyLive</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>spark streaming exactly-once analysis</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/08/27/spark-streaming-exactly-once-analysis/" rel="bookmark">
        <time class="entry-date published" datetime="2017-08-27T03:31:58.000Z">
          2017-08-27
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>最近对Spark Streaming接触比较多，主要关注的是streaming的准确性方面的需求, 忙了快半年，不禁想问为什么需要在exactly-once上花费这么多时间呢。streaming和batch的处理逻辑有什么区别呢？我觉得streaming更适合一些简单的过滤，能在100ms以内能算完的逻辑，而这些逻辑用batch也可以算完，为什么要streaming呢？用户们更希望的是更快。如果batch也能满足低延迟的需求，streaming系统就不需要了。而问题是为什么我们需要一个单独的streaming系统？<br><a id="more"></a></p>
<p> 生产环境中的版本是1.6，spark streaming的API在1.6上是基于RDD的DStream API，相比Structured Streaming，更稳定和成熟些。而我们的用户们，比较关心的是streaming系统</p>
<p> 开源里广泛使用的Streaming系统是Storm和Flink。Storm早期用record ack的方式保证at-least once，但没有提供exactly-once的保证，后面又有了storm trident.</p>
<h2 id="Spark-Streaming-Receiver模式没有exactly-once保证"><a href="#Spark-Streaming-Receiver模式没有exactly-once保证" class="headerlink" title="Spark Streaming Receiver模式没有exactly-once保证"></a>Spark Streaming Receiver模式没有exactly-once保证</h2><h2 id="Flink中的Exactly-Once保证"><a href="#Flink中的Exactly-Once保证" class="headerlink" title="Flink中的Exactly-Once保证"></a>Flink中的Exactly-Once保证</h2><h2 id="Storm的Eactly-Once保证"><a href="#Storm的Eactly-Once保证" class="headerlink" title="Storm的Eactly-Once保证"></a>Storm的Eactly-Once保证</h2><h3 id="Storm-Architecture"><a href="#Storm-Architecture" class="headerlink" title="Storm Architecture"></a>Storm Architecture</h3><p><img src="http://wx3.sinaimg.cn/mw690/761b7938ly1fizgwunfr6j21kw0n7e6n.jpg" alt="storm architecture"><br>以Storm on Yarn来说明Storm的架构：</p>
<ul>
<li>client将jar包通过yarn上传</li>
<li>在一台NodeManager上启动Nimbus，这是master节点，负责管理StormTopology, 分发task，心跳等</li>
<li>其他的NodeManager上启动Supervisor, 相当于slave节点，管理storm worker<ul>
<li>在每个supervisor上，可以启动多个worker进程，每个worker进程可以运行多个task，task是多线程的，由worker管理。这些task运行的就是Spout或Bolt定义的操作</li>
</ul>
</li>
<li>Zookeeper, Storm运行时状态的管理</li>
</ul>
<p>Storm方面算是简单调研，理解不是很深入，具体的参考<a href="http://storm.apache.org/releases/1.1.1/Setting-up-a-Storm-cluster.html" target="_blank" rel="external">官方文档</a></p>
<h3 id="Storm-exactly-once"><a href="#Storm-exactly-once" class="headerlink" title="Storm exactly-once"></a>Storm exactly-once</h3><p>####1. Storm Transactional Topologies(deprecated)<br>Strom 0.7版本中，实现了<a href="http://storm.apache.org/releases/1.1.1/Transactional-topologies.html" target="_blank" rel="external">transctional topologies</a>来保证exactly-once,<br><strong>1.transactional phrases 类似两阶段事务机制</strong></p>
<ul>
<li>The processing phase: this is the phase that can be done in parallel for many batches 可以并发执行计算partial result</li>
<li>The commit phase: The commit phases for batches are strongly ordered. So the commit for batch 2 is not done until the commit for batch 1 has been successful. 保证batch的提交是按顺序的</li>
</ul>
<p>来个直观的，用户需要构建的Topology如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">MemoryTransactionalSpout spout = <span class="keyword">new</span> MemoryTransactionalSpout(DATA, <span class="keyword">new</span> Fields(<span class="string">"word"</span>), PARTITION_TAKE_PER_BATCH);</div><div class="line">TransactionalTopologyBuilder builder = <span class="keyword">new</span> TransactionalTopologyBuilder(<span class="string">"global-count"</span>, <span class="string">"spout"</span>, spout, <span class="number">3</span>);</div><div class="line">builder.setBolt(<span class="string">"partial-count"</span>, <span class="keyword">new</span> BatchCount(), <span class="number">5</span>)</div><div class="line">        .shuffleGrouping(<span class="string">"spout"</span>);</div><div class="line">builder.setBolt(<span class="string">"sum"</span>, <span class="keyword">new</span> UpdateGlobalCount())</div><div class="line">        .globalGrouping(<span class="string">"partial-count"</span>);</div></pre></td></tr></table></figure>
<p><strong>2.关键点</strong></p>
<ul>
<li>一个拓扑里只有一个Transactional Spout，其实现是由一个单线程的Coordinator Spout + 多个Emitter Bolt组成。利用Storm的ACK Framework机制，判断一个batch是否执行完成</li>
<li>Committer Bolt 可以有多个，需要收到Transactional Spout的commit信息才会执行commit</li>
</ul>
<p>####2. Storm Trident Topologies<br>storm 1.1的版本中，引入新的Trident API解决exactly-once，这是transactional topologies的升级版本。API的易用性改善，exactly-once也是采用事务机制</p>
<p><strong>1.exactly once</strong></p>
<ul>
<li>Tuples are processed as small batches 采用micor-batch机制</li>
<li>Each batch of tuples is given a unique id called the “transaction id” (txid). If the batch is replayed, it is given the exact same txid. 每个batch有唯一的batchid</li>
<li>State updates are ordered among batches. That is, the state updates for batch 3 won’t be applied until the state updates for batch 2 have succeeded. 按txid顺序提交</li>
</ul>
<p><strong>2.trident example</strong><br><a href="https://github.com/lgrcyanny/LearningStorm/blob/master/src/main/scala/com/learning/storm/TridentTest.scala" target="_blank" rel="external">github example</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> topology = <span class="keyword">new</span> <span class="type">TridentTopology</span>()</div><div class="line"><span class="comment">// define spout</span></div><div class="line"><span class="keyword">val</span> spout = <span class="keyword">new</span> <span class="type">FixedBatchSpout</span>(<span class="keyword">new</span> <span class="type">Fields</span>(<span class="string">"sentence"</span>), <span class="number">3</span>,</div><div class="line">    <span class="keyword">new</span> <span class="type">Values</span>(<span class="string">"the cow jumped over the moon"</span>),</div><div class="line">    <span class="keyword">new</span> <span class="type">Values</span>(<span class="string">"the man went to the store and bought some candy"</span>),</div><div class="line">    <span class="keyword">new</span> <span class="type">Values</span>(<span class="string">"four score and seven years ago"</span>),</div><div class="line">    <span class="keyword">new</span> <span class="type">Values</span>(<span class="string">"how many apples can you eat"</span>))</div><div class="line">  spout.setCycle(<span class="literal">true</span>)</div><div class="line"></div><div class="line"><span class="keyword">val</span> wordsCount: <span class="type">TridentState</span> = topology.newStream(<span class="string">"wordsSpout"</span>, spout)</div><div class="line">    .each(<span class="keyword">new</span> <span class="type">Fields</span>(<span class="string">"sentence"</span>), <span class="keyword">new</span> <span class="type">Split</span>(), <span class="keyword">new</span> <span class="type">Fields</span>(<span class="string">"word"</span>))</div><div class="line">    .groupBy(<span class="keyword">new</span> <span class="type">Fields</span>(<span class="string">"word"</span>))</div><div class="line">    .persistentAggregate(<span class="keyword">new</span> <span class="type">MemoryMapState</span>.<span class="type">Factory</span>(), <span class="keyword">new</span> <span class="type">Count</span>(), <span class="keyword">new</span> <span class="type">Fields</span>(<span class="string">"count"</span>))</div><div class="line">    .parallelismHint(<span class="number">6</span>)</div></pre></td></tr></table></figure>
<p>###<strong>总结</strong></p>
<p>Storm里为了exacly once，需要做到：</p>
<ul>
<li>源端可重放</li>
<li>batch要有唯一的txid</li>
<li>commit时按顺序提交，类似事务的两阶段提交</li>
</ul>
<hr>








      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/spark-streaming/">spark streaming</a>
    </span>
    

    </div>

    
  </div>
</article>

  
	<section id="comments" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'lgrcyanny';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>





    </main>

    <footer class="site-footer">
  <p class="site-info">
    Copyright
    </br>
    
    &copy; 2017 Cyanny Liang
    
  </p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-40624708-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
</body>
</html>