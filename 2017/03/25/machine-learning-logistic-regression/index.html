<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning Logistic Regression | CyannyLive</title>

  
  <meta name="author" content="Cyanny Liang">
  

  
  <meta name="description" content="Do not go gentle into that good night">
  

  
  
  <meta name="keywords" content="Machine Learning">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="Machine Learning Logistic Regression"/>

  <meta property="og:site_name" content="CyannyLive"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="CyannyLive" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">CyannyLive</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>Machine Learning Logistic Regression</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/03/25/machine-learning-logistic-regression/" rel="bookmark">
        <time class="entry-date published" datetime="2017-03-25T13:48:51.000Z">
          2017-03-25
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>Logistic Regression is for classification problem, and the predication value is fixed descrete values, such as 1 for positive or 0 for negative. The essence of logistic regression is:</p>
<ul>
<li>hypothesis function is sigmoid function</li>
<li>cost function: J(theta)</li>
<li>gradient descent and algorithms</li>
<li>advantanced optimization with regularization to solve overfitting problem.<a id="more"></a>
<h2 id="Basics-about-logistic-regression"><a href="#Basics-about-logistic-regression" class="headerlink" title="Basics about logistic regression"></a>Basics about logistic regression</h2>hypothesis function = 1 / (1 + exp(-htheta(x))),<br>where htheta(x) = theta’ <em> x(theta’ is transpose theta)<br><img src="http://ww2.sinaimg.cn/mw690/761b7938jw1f2rxxio8x0j20v80nit9x.jpg" alt="Sigmoid Function or Logistic Function"><br>htheta(x) mean <em>*Probalitiy that y=1, given x parameterized by theta P(y=1 | x; theta)</em></em>,<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> htheta(x) &gt;= <span class="number">0.5</span>, then y = <span class="number">1</span></div><div class="line"><span class="keyword">if</span> htheta(x) &lt; <span class="number">0.5</span>, then y = <span class="number">0</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Descision-Boundary"><a href="#Descision-Boundary" class="headerlink" title="Descision Boundary"></a>Descision Boundary</h2><p><img src="http://ww3.sinaimg.cn/mw690/761b7938jw1f2rxxhyf4ij20v00ngtbs.jpg" alt="descision boundary"><br>Our goal is the calculate theta, can classify our traing data with descision boundary.<br>In the example, the traning data can be classified into 2 categories by a straight line.<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (theta'x) &gt;= <span class="number">0</span>, then htheta(x) &gt;= <span class="number">0.5</span>, then y = <span class="number">1</span></div><div class="line"><span class="keyword">if</span> (theta'x) &lt; <span class="number">0</span>, then htheta(x) &lt; <span class="number">0.5</span>, then y = <span class="number">0</span></div></pre></td></tr></table></figure></p>
<h2 id="Cost-function-implementation"><a href="#Cost-function-implementation" class="headerlink" title="Cost function implementation"></a>Cost function implementation</h2><p>For the assignment of week3, predicate the adimission by university with 2 exams grade data.<br>I optimize the implementation with vectoriaztion</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J, grad]</span> = <span class="title">costFunction</span><span class="params">(theta, X, y)</span></span></div><div class="line"><span class="comment">%COSTFUNCTION Compute cost and gradient for logistic regression</span></div><div class="line"><span class="comment">%   J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the</span></div><div class="line"><span class="comment">%   parameter for logistic regression and the gradient of the cost</span></div><div class="line"><span class="comment">%   w.r.t. to the parameters.</span></div><div class="line"></div><div class="line"><span class="comment">% Initialize some useful values</span></div><div class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></div><div class="line"></div><div class="line"><span class="comment">% You need to return the following variables correctly</span></div><div class="line">J = <span class="number">0</span>;</div><div class="line">grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(theta));</div><div class="line"></div><div class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></div><div class="line"><span class="comment">% Instructions: Compute the cost of a particular choice of theta.</span></div><div class="line"><span class="comment">%               You should set J to the cost.</span></div><div class="line"><span class="comment">%               Compute the partial derivatives and set grad to the partial</span></div><div class="line"><span class="comment">%               derivatives of the cost w.r.t. each parameter in theta</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">% Note: grad should have the same dimensions as theta</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">% Predications: h_theta(x)</span></div><div class="line">predications = sigmoid(X * theta);</div><div class="line">cost_items = y .* <span class="built_in">log</span>(predications) + (<span class="number">1</span> - y) .* <span class="built_in">log</span>(<span class="number">1</span> - predications);</div><div class="line">J = (<span class="number">-1</span> / m) * sum(cost_items);</div><div class="line"></div><div class="line">grad = (<span class="number">1</span> / m) * (X' * (hypothesis - y));</div><div class="line"></div><div class="line"><span class="comment">% =============================================================</span></div><div class="line"></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<h2 id="Cost-function-with-regularization"><a href="#Cost-function-with-regularization" class="headerlink" title="Cost function with regularization"></a>Cost function with regularization</h2><p>Regularzation is for overfitting problem.</p>
<ul>
<li>underfit: not fit the training data, with high bias between predications and actual value</li>
<li>Just Right: great fit</li>
<li>Overfitting:  often with too many features, not so much traning data, fit traing data well, but with hight variance, predict new data not very well</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J, grad]</span> = <span class="title">costFunctionReg</span><span class="params">(theta, X, y, lambda)</span></span></div><div class="line"><span class="comment">%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization</span></div><div class="line"><span class="comment">%   J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using</span></div><div class="line"><span class="comment">%   theta as the parameter for regularized logistic regression and the</span></div><div class="line"><span class="comment">%   gradient of the cost w.r.t. to the parameters.</span></div><div class="line"></div><div class="line"><span class="comment">% Initialize some useful values</span></div><div class="line">m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></div><div class="line"></div><div class="line"><span class="comment">% You need to return the following variables correctly</span></div><div class="line">J = <span class="number">0</span>;</div><div class="line">grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(theta));</div><div class="line"></div><div class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></div><div class="line"><span class="comment">% Instructions: Compute the cost of a particular choice of theta.</span></div><div class="line"><span class="comment">%               You should set J to the cost.</span></div><div class="line"><span class="comment">%               Compute the partial derivatives and set grad to the partial</span></div><div class="line"><span class="comment">%               derivatives of the cost w.r.t. each parameter in theta</span></div><div class="line">hypothesis = sigmoid(X * theta);</div><div class="line">cost_items = (y .* <span class="built_in">log</span>(hypothesis)) + (<span class="number">1</span> - y) .* <span class="built_in">log</span>(<span class="number">1</span> - hypothesis);</div><div class="line"><span class="comment">% don't penalize theta0</span></div><div class="line">reg_theta = [<span class="number">0</span>; theta(<span class="number">2</span>:length(theta))];</div><div class="line">J = (<span class="number">-1</span> / m) * sum(cost_items) + (lambda / (<span class="number">2</span> * m)) * sum(reg_theta .^ <span class="number">2</span>);</div><div class="line"><span class="comment">%grad = (1 / m) * sum((predications - y) .* X)' + (lambda / m) * penalize_theta;</span></div><div class="line">grad = (<span class="number">1</span> / m) * (X' * (hypothesis - y)) + (lambda / m) * reg_theta;</div><div class="line"></div><div class="line"><span class="comment">% =============================================================</span></div><div class="line"></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>the lambda for regularization can’t be too large:</p>
<ul>
<li>large lamba will got very small theta value, and underfit.</li>
<li>small lambda will got large theta velue, and overfit.</li>
<li>the lambda for the exerise is 1</li>
</ul>
<h2 id="Github-assignments"><a href="#Github-assignments" class="headerlink" title="Github assignments"></a>Github assignments</h2><p><a href="https://github.com/lgrcyanny/MachineLearningCoursera/tree/master/assignments/ex2-logistic-regression" target="_blank" rel="external">Week 3 Assignments</a></p>
<h2 id="Write-on-the-last"><a href="#Write-on-the-last" class="headerlink" title="Write on the last"></a>Write on the last</h2><p>After one year, I learn the logistic regression again. Last week, Andrew NG left Baidu. Maybe, these great people thought Baidu is not worth to fight for. Now I still decidated on a Spark project and focus on Spark Streaming. As team leader, I am bearing a great burden and is stressful. It’s a great chance to train my leadership. I am also wondering next opportunity. Learning Machine Learning is right and worth to do. Anyway, even though mist is on the path, just go forward and fight~</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/machine-learning/">Machine Learning</a>
    </span>
    

    </div>

    
  </div>
</article>

  
	<section id="comments" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'lgrcyanny';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>





    </main>

    <footer class="site-footer">
  <p class="site-info">
    Copyright
    </br>
    
    &copy; 2018 Cyanny Liang
    
  </p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-40624708-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
</body>
</html>