<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Page 3 | CyannyLive | AI and Big Data</title>

  
  <meta name="author" content="Cyanny Liang">
  

  
  <meta name="description" content="Wisdom comes from inside">
  

  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  

  <meta property="og:site_name" content="CyannyLive"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="CyannyLive" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">CyannyLive</a>
    </h1>
    <p class="site-description">AI and Big Data</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about/">About</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    
  <article>

  
    
    <h3 class="article-title"><a href="/2015/10/07/learning-akka/"><span>Learning Akka</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/07/learning-akka/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-07T13:54:48.000Z">
          2015-10-07
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>最近学习了scala，主要是跟着<strong>Functional Programming in Scala</strong>的课程学习的，scala主要的用处还是在spark上，关于spark也看了一些源码，处于继续探索中。</p>
<p>并发时的消息通信是处理spark这样的分布式系统的关键。spark主要依赖scala社区的akka进行消息通讯。在spark1.2的代码中可以看到很多actor的影子，然而spark1.4中，都是封装为EndPoint，但Actor的思想和模式还在。</p>
<p>基于Actor的消息通讯模型是akka的核心。Akka为处理并发、容错和可扩展性的分布式问题提供了一套基于Actor模型的库。并发的消息通讯中，抽象是关键的方面。Actor模型是1973年由Carl Hewitt在论文”Actor Model of Computation- Scalable Robust Information Systems”中提出, 后被应用于爱立信公司研发的Elang语言，爱立信公司应用Actor模型开发了高并发和可靠的通信系统。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/akka/">Akka</a><a href="/tags/scala/">Scala</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2015/10/07/learning-akka/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2015/05/04/bitsort-ant-qsort/"><span>位排序和快排</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/05/04/bitsort-ant-qsort/" rel="bookmark">
        <time class="entry-date published" datetime="2015-05-04T13:57:53.000Z">
          2015-05-04
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>这已经不是一个新话题了，但是从开始实现一个C++位排序和快排，我还是花费了2个多小时，这里就记下自己的一点点体会啦。</p>
<p>首先，题目来自《编程珠玑》第一章，主要是做位排序，同时和快排做比较：</p>
<p>1. 实现位逻辑运算，实现位向量，并用该位向量实现1,000,000个数字的排序，数字最大是10,000,000</p>
<p>2. 实现1000,000个数字的快排序</p>
<p>3. 实现生成小于n且没有重复的k个整数，这里n=10,000,000, k = 1,000,000</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/algorithm/">Algorithm</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2015/05/04/bitsort-ant-qsort/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2015/04/03/find-median-for-two-sorted-array/"><span>查找两个排序数组的中位数</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/04/03/find-median-for-two-sorted-array/" rel="bookmark">
        <time class="entry-date published" datetime="2015-04-03T14:07:01.000Z">
          2015-04-03
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>题目是：求两个排序数组的中位数。<br>设：两个排序的数组a[m], b[n]，求a和b数组的中位数。<br>算法是：<br>mid_a是数组a的中位数index，同理mid_b是数组b的中位数索引<br>1. 如果a[mid_a] == b[mid_b] 中位数为a[mid_a]</p>
<p>2. 如果a[mid_a] &lt; b[mid_b], 递归查找a(mid_a + 1, m - 1), b(0, mid_b)，因为a[mid_a]比较小，不可能作为下一次查询的中位数</p>
<p>3. 如果a[mid_a] &gt; b[mid_b], 递归查找a(0, mid_a), b(mid_b + 1, n - 1)，因为b[mid_b]比较小，不可能作为下一次查询的中位数</p>
<p>4. 当只少于4个元素需要查找时递归停止，merge这少于4的元素，求出中位数。这里需要考虑奇偶数的情况，只剩下2个或3个元素，不如只考虑4个简单。</p>
<p>注意：这里求上中位数，当n为奇数时，中位数是唯一的，出现位置为n/2；当n为偶数时候，存在两个中位数，数组index从0开始，位置分别为n/2 - 1（上中位数）和n/2（下中位数）。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/algorithm/">Algorithm</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/algorithm/">algorithm</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2015/04/03/find-median-for-two-sorted-array/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/08/16/hive-architecture/"><span>Hive架构笔记</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/08/16/hive-architecture/" rel="bookmark">
        <time class="entry-date published" datetime="2014-08-16T15:32:27.000Z">
          2014-08-16
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>Hive是基于Hadoop的大数据查询引擎, 存储于HDFS上的数据,要求开发者采用MR才能进行计算, 但MR是low-level的分布式计算,对于复杂的分析job, 多重MR是很复杂的, Hive致力于让用户采用传统的RDBMS的SQL查询处理分布式的大数据.</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/hadoop/">Hadoop</a>, <a href="/categories/hadoop/hive/">Hive</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/hadoop/">Hadoop</a><a href="/tags/hive/">Hive</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/08/16/hive-architecture/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/04/12/dijkstra-algorithm-in-java/"><span>Dijkstra Algorithm</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/04/12/dijkstra-algorithm-in-java/" rel="bookmark">
        <time class="entry-date published" datetime="2014-04-12T03:55:04.000Z">
          2014-04-12
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>计算单源最短路径的算法有Bellman-Ford算法，主要是计算带负权有向图的单源最短路径。第二种算法：对于DAG图（Directed Acyclic Graph, 有向无环图）可以通过拓扑排序后再计算单源最短路径。第三，可以使用BFS(广度优先搜索)计算单源最短路径。第四，就是著名的Dijkstra算法，要求有向图的所有边的权值非负，当然图可以不是DAG图。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/algorithm/">Algorithm</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/algorithm/">algorithm</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/04/12/dijkstra-algorithm-in-java/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/03/20/hbase-mapreduce-e6-8e-92-e5-ba-8f-secondary-sort/"><span>HBase MapReduce排序Secondary Sort</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/03/20/hbase-mapreduce-e6-8e-92-e5-ba-8f-secondary-sort/" rel="bookmark">
        <time class="entry-date published" datetime="2014-03-20T10:51:08.000Z">
          2014-03-20
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>MapReduce是Hadoop中处理大数据的方法，是一个处理大数据的简单算法、编程泛型。虽然思想简单，但其实真正用起来还是有很多问题，不是所有的问题都可以像WordCount那样典型和直观, 有很多需要trick的地方。MapReduce的中心思想是分而治之，数据要松耦合，可以划分为小数据集并行处理，如果数据本身在计算上存在很强的依赖关系，就不要赶鸭子上架，用MapReduce了。<br>MapReduce编程中，最重要的是要抓住Map和Reduce的input和output，好的input和output可以降低实现的复杂度。最近，写了很多关于MapReduce的job，有倒排索引，统计，排序等。其中，对排序花费了一番功夫，MapReduce做WordCount很好理解,<br>Map input:[offset, text],  output: [word, 1],</p>
<p>Reduce input: [word, 1], output: [word, totalcount],还可以设置Combiner进行优化。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/hadoop/">Hadoop</a>, <a href="/categories/hadoop/hbase/">HBase</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/hadoop/">Hadoop</a><a href="/tags/hbase/">HBase</a><a href="/tags/mapreduce/">MapReduce</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/03/20/hbase-mapreduce-e6-8e-92-e5-ba-8f-secondary-sort/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/03/13/hbase-architecture-analysis-part-3-pros-cons/"><span>HBase Architecture Analysis Part 3 Pros and Cons</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/03/13/hbase-architecture-analysis-part-3-pros-cons/" rel="bookmark">
        <time class="entry-date published" datetime="2014-03-13T14:13:20.000Z">
          2014-03-13
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="5-HBase-Physical-Architecture"><a href="#5-HBase-Physical-Architecture" class="headerlink" title="5. HBase Physical Architecture"></a>5. HBase Physical Architecture</h2><p>Figure 5.1 shows the deployment view for HBase cluster:<br>HBase is the master-slave cluster on top of HDFS. The classic deployment is as follows:<br>➢** Master node:** one HMaster and one NameNode running on a machine as the master node.<br>➢ <strong>Slave node:</strong> Each node is running one HRegionServer and one DataNode. And each node report status to the master node and Zookeeper.<br>➢** Zookeeper:** HBase is shipped with ensemble Zookeeper, but for large clusters, using existing Zookeeper is better. Zookeeper is crucial, the HMaster and HRegionServers will register on Zookeeper.<br>➢ <strong>Client</strong>: There can be many clients to access HRegionServer, like Java Client, Shell Client, Thrift Client and Avro Client</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/hadoop/">Hadoop</a>, <a href="/categories/hadoop/hbase/">HBase</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/hadoop/">Hadoop</a><a href="/tags/big-data/">Big Data</a><a href="/tags/hbase/">HBase</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/03/13/hbase-architecture-analysis-part-3-pros-cons/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/03/13/hbase-architecture-analysis-part2-process-architecture/"><span>HBase Architecture Analysis Part2(Process Architecture)</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/03/13/hbase-architecture-analysis-part2-process-architecture/" rel="bookmark">
        <time class="entry-date published" datetime="2014-03-13T14:00:11.000Z">
          2014-03-13
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="4-Process-Architecture"><a href="#4-Process-Architecture" class="headerlink" title="4. Process Architecture"></a>4. Process Architecture</h2><h3 id="4-1-HBase-Write-Path"><a href="#4-1-HBase-Write-Path" class="headerlink" title="4.1 HBase Write Path"></a>4.1 HBase Write Path</h3><p>The client doesn’t write data directly into HFile on HDFS. Firstly it writes data to WAL(Write Ahead Log), and Secondly, writes to MemStore shared by a HStore in memory.</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/hadoop/">Hadoop</a>, <a href="/categories/hadoop/hbase/">HBase</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/hadoop/">Hadoop</a><a href="/tags/big-data/">Big Data</a><a href="/tags/hbase/">HBase</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/03/13/hbase-architecture-analysis-part2-process-architecture/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/03/13/hbase-architecture-analysis-part1-logical-architecture/"><span>HBase Architecture Analysis Part1(Logical Architecture)</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/03/13/hbase-architecture-analysis-part1-logical-architecture/" rel="bookmark">
        <time class="entry-date published" datetime="2014-03-13T13:18:32.000Z">
          2014-03-13
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h2><p>Apache HBase is an open source column-oriented database. <strong>It is often described as a sparse, consistent, distributed, multi-dimensional sorted map.</strong> HBase is modeled after Google’s “Bigtable: A distributed Storage System for Structured Data”, which can host very large tables with billions of rows, X millions of columns.</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/hadoop/">Hadoop</a>, <a href="/categories/hadoop/hbase/">HBase</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/hadoop/">Hadoop</a><a href="/tags/big-data/">Big Data</a><a href="/tags/hbase/">HBase</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/03/13/hbase-architecture-analysis-part1-logical-architecture/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2014/02/27/nodejs-hbase-hadoop2-thrift2-e9-85-8d-e7-bd-ae-e4-b8-8e-e4-bd-bf-e7-94-a8/"><span>Nodejs HBase0.96 Hadoop2.2.0 Thrift2配置与使用</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2014/02/27/nodejs-hbase-hadoop2-thrift2-e9-85-8d-e7-bd-ae-e4-b8-8e-e4-bd-bf-e7-94-a8/" rel="bookmark">
        <time class="entry-date published" datetime="2014-02-27T08:00:42.000Z">
          2014-02-27
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>项目如果没有采用Java开发，难道就不能用HBase了么？程序猿不会善罢甘休的，有什么语言就会有什么API存在，我还觉得用Java配置时各种缺包错误很烦呢，记得《数学之美》中曾说道：“做技术有术和道两个层面”，知道HBase的架构和一些底层细节是”道”，而使用各种配置和API开发应用则是”术”，而我们就来试试非Java连接HBase。<br>HBase的第三方接口有Shell, Java, REST和Thrift，可以参考《HBase in Action》chapter 6, REST接口比较慢，使用起来并没有Thrift好。而你可能疑惑什么是Thrift:</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/hadoop/">Hadoop</a>, <a href="/categories/hadoop/hbase/">HBase</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/hadoop/">Hadoop</a><a href="/tags/hbase/">HBase</a><a href="/tags/learn/">Learn</a>
    </span>
    

    </div>

    
    <div class="article-meta pull-right">
      <span>
        <i class="icon-comments"></i>
        <span>
          <a href="/2014/02/27/nodejs-hbase-hadoop2-thrift2-e9-85-8d-e7-bd-ae-e4-b8-8e-e4-bd-bf-e7-94-a8/#comment">Comments</a>
        </span>
      </span>
    </div>
    
  </div>
</article>




<nav class="pagination">
  
  <a href="/page/2/" class="pagination-prev">Prev</a>
  
  
  <a href="/page/4/" class="pagination-next">Next</a>
  
</nav>
    </main>

    <footer class="site-footer">
  <p class="site-info">
    Copyright
    </br>
    
    &copy; 2021 Cyanny Liang
    
  </p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-40624708-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
</body>
</html>